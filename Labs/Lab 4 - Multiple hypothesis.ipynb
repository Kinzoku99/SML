{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwGqN5_Q4162"
   },
   "source": [
    "## Data & library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7112,
     "status": "ok",
     "timestamp": 1696421225006,
     "user": {
      "displayName": "Michał Ciach",
      "userId": "00832457977902949614"
     },
     "user_tz": -120
    },
    "id": "7c1qctHRoY_V",
    "outputId": "3274ad66-c86b-4184-b416-cd3501f9b486"
   },
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5060,
     "status": "ok",
     "timestamp": 1696421230060,
     "user": {
      "displayName": "Michał Ciach",
      "userId": "00832457977902949614"
     },
     "user_tz": -120
    },
    "id": "jS4Mwv37_lgM",
    "outputId": "8bbf08c6-e7d0-46b5-e54b-93188d7b5034"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1xOJfD-jexDbHSOCg1EiyAxqc5kXjMvX0\n",
    "!gdown https://drive.google.com/uc?id=1y5NKR3aWB0DbAuSWcg6ffa1Atu2unpOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1696421230060,
     "user": {
      "displayName": "Michał Ciach",
      "userId": "00832457977902949614"
     },
     "user_tz": -120
    },
    "id": "1qclcOYOz3qg"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2379,
     "status": "ok",
     "timestamp": 1696421232437,
     "user": {
      "displayName": "Michał Ciach",
      "userId": "00832457977902949614"
     },
     "user_tz": -120
    },
    "id": "EkH7lfBv405O"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from scipy.stats import t as tstud\n",
    "from scipy.stats import ttest_ind, ttest_rel, ttest_1samp, norm, kstest, mannwhitneyu, shapiro, chisquare, chi2_contingency\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.stats.multitest import fdrcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1696421233149,
     "user": {
      "displayName": "Michał Ciach",
      "userId": "00832457977902949614"
     },
     "user_tz": -120
    },
    "id": "QFOe8o1n41Ec",
    "outputId": "e6ba8473-9548-4ba1-e8f7-533dfab1b385"
   },
   "outputs": [],
   "source": [
    "protein_lengths = pd.read_csv('protein_lengths.tsv', sep='\\t')\n",
    "protein_lengths['LogLength'] = np.log10(protein_lengths['Protein length'])\n",
    "protein_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1696421233151,
     "user": {
      "displayName": "Michał Ciach",
      "userId": "00832457977902949614"
     },
     "user_tz": -120
    },
    "id": "QVYnO3rm_sSc",
    "outputId": "55a02c04-5591-4d1a-987b-70800c838672"
   },
   "outputs": [],
   "source": [
    "human_protein_lengths = protein_lengths.loc[protein_lengths['Common name'] == 'Human'].copy()\n",
    "# Note: without .copy(), some versions of Pandas may return a View.\n",
    "# This may interfere with adding a new column to human_protein_lengths.\n",
    "print(human_protein_lengths.head())\n",
    "print()\n",
    "print(human_protein_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1696421233152,
     "user": {
      "displayName": "Michał Ciach",
      "userId": "00832457977902949614"
     },
     "user_tz": -120
    },
    "id": "Fs8D4zlT1pTm",
    "outputId": "8d6e4d7a-a1b1-44c6-b2a2-3edf4fa0f7a4"
   },
   "outputs": [],
   "source": [
    "citizen_incomes = pd.read_csv('citizen incomes.tsv', sep='\\t')\n",
    "citizen_incomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETOqr5vCrkEA"
   },
   "source": [
    "## Multiple hypothesis testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iILC41JzPcxc"
   },
   "source": [
    "When performing statistical tests, we reject the null hypothesis when the p-value is below a set threshold, traditionally 0.05. A consequence of this approach is that 5% of positive results will be false positives (Type I errors; incorrect rejections of a true null hypothesis), which may be a huge number when thousands of tests are performed in large-scale studies.  \n",
    "\n",
    "In order to limit the number of false positives, we use *multiple testing corrections*. One of the most useful ones is the Benjamini-Hochberg correction, which controls the False Discovery Rate (FDR), i.e. the proportion of false positives among all positive results. Note the difference from significance levels: the false discovery rate is the proportion of false positives among all positives in the *results* of the tests, while the significance level is the proportion of false positives among the *true negatives* (cases when $H_0$ is true).  \n",
    "\n",
    "The assumptions and details of the Benjamini-Hochberg correction (and other common corrections) were discussed in the lecture; you may want to review them now. One of the most important assumptions is that the p-values come from a set of independent tests.  \n",
    "\n",
    "A common way to perform the Benjamini-Hochberg correction is to transform the p-values $p_1, \\dots, p_m$ in a way to obtain so-called *q-values* $q_1, \\dots, q_m$, such that we have an FDR on the level of $Q$ when we accept all hypotheses $H_i$ with $q_i \\leq Q$.\n",
    "\n",
    "\n",
    "Do not confuse the False Discovery Rate (FDR) with other similarly named metrics, like the False Positive Rate (FPR)! FDR is the ratio of the number of false positives to the number of all reported positives, while FPR is the ratio of the number of false positives to the number of true null hypotheses. You can see a list of other common metrics [here](https://en.wikipedia.org/wiki/Confusion_matrix).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKBr6c7ttByS"
   },
   "source": [
    "In the next exercise, we will use *stochastic simulations* to generate our own data. First, however, let's talk about what it means to simulate a random variable.  \n",
    "\n",
    "*Theory time.* The term *simulating a random variable* is confusing for many students, especially the ones that paid attention in probability classes. Recall that a random variable $X$ is a function from the space of elementary outcomes $\\Omega$ to the space of real (or integer) numbers. When some students hear \"let's simulate a sequence of random variables $X_1, \\dots, X_n$, they wonder: how do we simulate a sequence of functions? Well, this is not what we mean at all.   \n",
    "\n",
    "We define random variables as functions because we want to have a mathematical model of randomness. This is a convenient way to rigorously define what it means that a variable $X$ takes some value with some probability. For example, we can use it to formally define $\\mathbb{P}(X=1) = \\mathbb{P}(\\{ \\omega: X(\\omega)  =1 \\})$. We need this definition, because the concept of probability is defined on the space $\\Omega$, not on the real numbers. However, this is not how we interpret or use random variables in practice.\n",
    "\n",
    "Recall that the number of dots on a set of dice is a sequence of random variables $X_1, \\dots, X_n$ before you throw the dice. When you throw them, you get realizations of the random variables, $X_1(\\omega), \\dots, X_n(\\omega)$, which are a sequence of numbers (and often called *random numbers*). Measuring the outcome of a random experiment corresponds to fixing $\\omega$ in a sequence of random variables. This is why we can interpret random variables as numerical variables. Defining them as functions is necessary only because otherwise terms like $\\mathbb{P}(X=1)$ don't have any mathematical meaning.\n",
    "\n",
    "\"Fixing $\\omega$\" is also what we mean by simulating a sequence of random variables: we want to get a sequence of numbers $x_1, \\dots, x_n$ that are realizations of a sequence of random variables $X_1, \\dots X_n$, so that $x_i = X_i(\\omega)$. However, simulating doesn't mean that we pick $\\omega$ by hand. Remember that $\\omega$ is mostly a mathematical model, not a physical being. Instead of selecting it by hand, we rely on random number generators that \"fix $\\omega$\" for us.   \n",
    "\n",
    "You have already encountered a few random number generators. A set of dice is one of them. When you throw the dice, you can imagine that the action of throwing corresponds to fixing $\\omega$ in a sequence of random variables - and you get a sequence of numbers as a result. You probably have also used pseudo-random number generators in your programs. These are algorithms that return pseudo-random numbers between 0 and 1. When you run this algorithm, you can imagine that this corresponds to fixing $\\omega$ in a random variable $X\\sim U([0, 1])$ - and you get a random number as a result.   \n",
    "\n",
    "These two random number generators (the dice and the algorithm) return numbers with very simple distributions. However, we can simulate random numbers with many other distributions, such as the Normal one. There are many techniques to do this, which usually rely on transforming random numbers distributed uniformly between 0 and 1 (formally speaking, numbers which are a realization of a sequence of random variables $X_i$ such that $X_i \\sim_{iid} U([0, 1])$). In this course, you don't need to worry about these techniques: we will simulate random variables using algorithms which are already implemented in Python libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSM59hWBC2NP"
   },
   "source": [
    "**Exercise 1.** In this exercise, we'll learn how to use the Benjamini-Hochberg correction to control the False Discovery Rate, as well as how to simulate our own data sets. We will generate a set of samples from two different distributions and test for the value of their means, resulting in a set of tests in which some null hypotheses are true, and some are false.  \n",
    "\n",
    "1. Generate $M=1000$ random samples of size $N=10$ from the standard normal distribution, and $M=1000$ samples of size $N=10$ from the normal distribution with expected value $\\mu=1$. Use the `norm.rvs` function from `scipy` (if you need to, you can look for its documentation online).\n",
    "2. For each sample, do a one-sample Student's t test to check whether the mean is equal zero. Save the p-values.      \n",
    "  2.1. How many null hypotheses are true, and how many are false?   \n",
    "3. Reject the null hypotheses on the significance level 5% (i.e. when the p-values are less than 0.05).   \n",
    "  3.1. How many positive results (i.e. rejections of the null hypothesis) did you get?  \n",
    "  3.2. How many true positives did you get?  \n",
    "  3.3. How many false positives did you get?  \n",
    "  3.4. How many false positives did you expect given the significance level?   \n",
    "  3.5. Calculate the obtained False Positive Rate. Is it close to the significance level? Why/why not?       \n",
    "  3.6. Calculate the obtained False Discovery Rate.     \n",
    "  3.7. Which of the previous points depend on $N$? Which do depend on $M$? Give a theoretical argument.   \n",
    "4. Perform the Benjamini-Hochberg correction on your p-values using the `fdrcorrection` function from the `statsmodels` library. Reject the null hypothesis at the FDR level 10%.  \n",
    "  4.1. How many positive results did you get?  \n",
    "  4.2. How many true positives did you get?  \n",
    "  4.3. How many false positives did you get?  \n",
    "  4.4. Calculate the obtained False Positive Rate. Is it close to the significance level? Why/why not?     \n",
    "  4.5. Calculate the obtained False Discovery Rate. Is it close to the assumed 10% FDR? Why/why not?  \n",
    "  4.6. How many false positives did you expect given the FDR level?  \n",
    "5. Suppose all the samples were drawn from the standard normal distribution. What would be the effect of applying the Benjamini-Hochberg correction? How many false positives would you expect to obtain?    \n",
    "6. \\* Based on the description of the Benajmini-Hochberg procedure from [this Wikipedia article](https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini%E2%80%93Hochberg_procedure), figure out how to compute the q-values given a list of p-values. Write a function that accepts a vector of p-values and returns the corresponding q-values. Compare your results to the `fdrcorrection` function from the `statsmodels` library on a p-value vector (0.01, 0.1, 0.01, 0.2, 0.01, 0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1693754573931,
     "user": {
      "displayName": "Michał Ciach",
      "userId": "00832457977902949614"
     },
     "user_tz": -120
    },
    "id": "_GouSvnSH1kv",
    "outputId": "b4f032c2-44a7-4b91-bb64-1228f75ffdeb"
   },
   "outputs": [],
   "source": [
    "## BH implementation\n",
    "test_p = [0.01, 0.1, 0.01, 0.2, 0.01, 0.1]\n",
    "def BH_correct(p):\n",
    "  p = np.array(p)\n",
    "  order = np.argsort(p)\n",
    "  p = p[order]\n",
    "  q = p*len(p)/range(1, len(p)+1)\n",
    "  for i in range(len(q)-1, 0, -1):\n",
    "    if q[i-1] > q[i]:\n",
    "      q[i-1] = q[i]\n",
    "  p[order] = q  # ideally we'd write q[order] = q, but this would mess up the array\n",
    "                # because in this case numpy modifies the array during the assignment operation\n",
    "  return p\n",
    "print('My q-values:', BH_correct(test_p))\n",
    "print('Statsmodels:', fdrcorrection(test_p)[1])\n",
    "\n",
    "## Simulation\n",
    "M = 1000\n",
    "N = 10\n",
    "samples = np.vstack(\n",
    "    (\n",
    "        norm.rvs(size=(M, N), loc=0.),\n",
    "        norm.rvs(size=(M, N), loc=1.)\n",
    "    )\n",
    ")\n",
    "null_is_true = np.array([True]*M + [False]*M)\n",
    "\n",
    "# Testing each distinct pair\n",
    "# (the correct way)\n",
    "print()\n",
    "print('Testing')\n",
    "pvals = []\n",
    "for i in range(2*M):\n",
    "  test = ttest_1samp(samples[i], 0.)\n",
    "  pvals.append(test[1])\n",
    "print('Number of tests done:', len(pvals))\n",
    "# Ordinary testing\n",
    "positive = np.array([p < 0.05 for p in pvals])\n",
    "TP = sum(positive*(~null_is_true))\n",
    "FP = sum(positive*null_is_true)\n",
    "TN = sum((~positive)*null_is_true)\n",
    "P = TP + FP\n",
    "print('Number of positives:', P)\n",
    "print('Number of true positives:', TP)\n",
    "print('Number of false positives:', FP)\n",
    "print('\"Raw\" FPR:', FP/(FP+TN))\n",
    "print('\"Raw\" FDR:', FP/P)\n",
    "# HB correction\n",
    "HB_positive = fdrcorrection(pvals, 0.1)[0]\n",
    "HB_TP = sum(HB_positive*(~null_is_true))\n",
    "HB_FP = sum(HB_positive*null_is_true)\n",
    "HB_TN = sum(~(HB_positive)*null_is_true)\n",
    "HB_P = HB_FP + HB_TP\n",
    "print('HB number of positives:', HB_P)\n",
    "print('HB number of true positives:', HB_TP)\n",
    "print('HB number of false positives:', HB_FP)\n",
    "print('HB FPR:', HB_FP/(HB_FP+HB_TN))\n",
    "print('HB FDR:', HB_FP/HB_P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzz2rXQilVfJ"
   },
   "source": [
    "**Exercise 2.\\*** In the previous exercise, you may have noticed that the results vary between the runs. Each sampling of the $2M$ samples returns a different FDR. In this exercise, we'll analyze the distribution of the FDR.  \n",
    "1. Repeat the calculation of the \"raw\" FDR (i.e. before the correction) and the \"BH\" FDR (after the correction) for $R=1000$ times. Also calculate the True Positive Rate, i.e. the fraction of correctly identified positives.  \n",
    "2. Generate histograms that compare the FDR and TPR before and after the BH correction.     \n",
    "  2.1. Is there any adverse effect to using the Benjamini-Hochberg correction?  \n",
    "3. Calculate the average FDR after the correction. Is it close to the assumed 10% level? Why/why not?       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2iJxmlLiu0e"
   },
   "source": [
    "**Exercise 2.** In each of the research experiments below, there is either some procedure applied incorrectly, or it is correct but can be improved. For each point, say whether all the assumptions are satisfied, and whether the methodology can be improved (e.g. by using a different statistical test or correction procedure). If the assumptions are violated, discuss the possible effect of this kind of violation. For extra points, support your claims with theoretical arguments or simulations.        \n",
    "1. A researcher studies the effect of glucose consumption on rat well-being. The researcher has partitioned $N=20$ rats into two groups: an experimental one with excess glucose in the diet, and a control one with a normal diet. After a week, the researcher has measured the weight of the rats, the length of sleep, the blood glucose level, the abdominal circumference, the body fat percentage, and the anxiety level (using the elevated plus maze assay). The researcher has compared each factor between the experimental and the control group using the two-sample Student's t test for unpaired observations, previously verifying that the compared variables are normally distributed using the Shapiro-Wilk's test. Next, the researcher has corrected the Student's t test p-values for multiple testing using the Benjamini-Hochberg correction at FDR level 20%.   \n",
    "2. A researcher studies the effect of consumption of small amounts of vinegar on the increase of the blood glucose level (BGC) in mice. The researcher has partitioned $N=20$ mice into equally-sized experimental and control groups. At the beginning of the experiment, he has measured the BGC of all mice. Next, for four days, mice from both group were given a diet enriched in glucose. Mice from the experimental groups were also given small amounts of vinegar in their diet. After four days, the BGC of all mice was measured again. Next, in each group, the researcher has tested for the increase in BGC using a two-sample Student's t-test for unpaired observations.  \n",
    "3. A researcher studies the effect of artificial sweeteners on the blood glucose level (BGC) in mice. The researcher has partitioned $N=100$ mice into ten equally-sized groups: nine experimental and one control. Mice in the control group were given a normal diet. In the experimental groups, the mice were given food enriched in glucose; sucralose; aspartam; erythritol; stevia; xylitol; saccharine; acesulfam K; manninol. After four days, the researcher has measured the BGC of all mice. Next, the researcher has used the two-sample Student's t test for unpaired observations to compare the average BGC between the ten groups. To correct for multiple tests, the researcher has used the Benjamini-Hochberg procedure at FDR level 20%.      \n",
    "4. A researcher studies the effect of salt consumption on the abdominal circumference (AC) in mice. The researcher has partitioned $N=20$ mice into equally-sized experimental and control groups. The AC of all mice was measured at the beginning of the experiment. Mice from the experimental group were given a diet enriched in salt. After a week, the AC was measured again, and the researcher used a two-sample Student's t test for paired observations in each group. The results of the test in each group were insigificant, and the researcher concluded that salt consumption does not increase the abdominal circumference in the span of one week.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ad. 1. Incorrect. Some of the measurements are naturally correlated (weight and abdominal circumference; abdominal circumference and fat percentage), and the BH correction assumes independent tests. However, in this case, the BH correction should give conservative results rather than false ones, because the measurements are positively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M060dORLUS7a"
   },
   "source": [
    "<center><img src='https://drive.google.com/uc?export=view&id=12CrUdXDAiltLBT26sG7HZ_HciIhvGyT8'></center>|"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
